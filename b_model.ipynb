{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PLEASE READ INSTRUCTIONS ON HOW TO RUN REQUIREMENTS.TXT FILE\n",
    "\n",
    "Transformers is package to clean, reduce, expand or generate features\n",
    "Contains thousands of pre-trained models for text, vision, and audio.\n",
    "'''\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import re\n",
    "from os.path import exists\n",
    "'''\n",
    "Google translate API package import\n",
    "'''\n",
    "import googletrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline type selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# Object encapsulating the sentiment analysis pipeline via identifier\n",
    "# Helps to clasify sequences according to positive or negative sentiments\n",
    "senti_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline performance example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9994329810142517}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive statement\n",
    "senti_pipeline(\"I am extremely happy people have found refuge and food after the disaster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9983866214752197}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative statement\n",
    "senti_pipeline(\"I am sad that the government has not provided more assistance to the affected after the hurricane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline on each english tweet within hurricane ian tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english sentiment analysis file already created\n"
     ]
    }
   ],
   "source": [
    "if not exists(\"sa_tweets_eng_original.csv\"):\n",
    "    \n",
    "    # Read csv containing tweets in english\n",
    "    dataset = pd.read_csv('hurricane_ian.csv')\n",
    "    # Create new dataframe containing results and save tweets there\n",
    "    results = pd.DataFrame()\n",
    "    results['tweet'] = dataset['tweet']\n",
    "\n",
    "    labels = []\n",
    "    scores = []\n",
    "\n",
    "    # Go through each tweet and evaluate\n",
    "    for tweet in results['tweet']:\n",
    "        ans = senti_pipeline(tweet)\n",
    "        # Append each dictionary result to corresponding list\n",
    "        labels.append(ans[0]['label'])\n",
    "        scores.append(ans[0]['score'])\n",
    "\n",
    "    # Create a column with list transformed into pd series\n",
    "    results['label'] = pd.Series(labels)\n",
    "    results['score'] = pd.Series(scores)\n",
    "\n",
    "    # Store results on new csv\n",
    "    results.to_csv('sa_tweets_eng_original.csv')\n",
    "else:\n",
    "    # Read csv containing tweets in english with already created scoring and labels\n",
    "    results = pd.read_csv('sa_tweets_eng_original.csv')\n",
    "    print(\"english sentiment analysis file already created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate english tweets into Spanish using Google Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google translate available languages\n",
    "# print(googletrans.LANGUAGES)\n",
    "#'es' for spanish and 'en' for english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create translator class object\n",
    "translator = googletrans.Translator()\n",
    "# List to store tweets in spanish\n",
    "spanish = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass each tweet as a parameter into the translator object and store results\n",
    "if not exists(\"sa_tweets_sp_translated.csv\"):\n",
    "    # Create new dataframe to store spanish tweets\n",
    "    spanish_tweets = pd.DataFrame()\n",
    "    for tweet in results['tweet']:\n",
    "        spanish.append(translator.translate(tweet))\n",
    "    # Create column containing translated tweets\n",
    "    spanish_tweets['tweet'] = pd.Series(spanish)\n",
    "    spanish_tweets.to_csv(\"sa_tweets_sp_translated.csv\")\n",
    "else:\n",
    "    spanish_tweets = pd.read_csv('sa_tweets_sp_translated.csv')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PLEASE READ INSTRUCTIONS ON HOW TO RUN REQUIREMENTS.TXT FILE\n",
    "\n",
    "Transformers is package to clean, reduce, expand or generate features\n",
    "Contains thousands of pre-trained models for text, vision, and audio.\n",
    "'''\n",
    "from transformers import pipeline\n",
    "'''\n",
    "Pysentimiento is part of the transformers trained models that applies sentiment analysis to spanish texts\n",
    "'''\n",
    "import pandas as pd\n",
    "import re\n",
    "from os.path import exists\n",
    "'''\n",
    "Google translate API package import\n",
    "'''\n",
    "import googletrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline type selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# Object encapsulating the sentiment analysis pipeline via identifier\n",
    "# Helps to clasify sequences according to positive or negative sentiments\n",
    "senti_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline performance example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9994329810142517}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive statement\n",
    "senti_pipeline(\"I am extremely happy people have found refuge and food after the disaster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9983866214752197}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative statement\n",
    "senti_pipeline(\"I am sad that the government has not provided more assistance to the affected after the hurricane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline on each english tweet within hurricane ian tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english sentiment analysis file already created\n"
     ]
    }
   ],
   "source": [
    "if not exists(\"sa_tweets_eng_original.csv\"):\n",
    "    \n",
    "    # Read csv containing tweets in english\n",
    "    dataset = pd.read_csv('hurricane_ian.csv')\n",
    "    # Create new dataframe containing results and save tweets there\n",
    "    results = pd.DataFrame()\n",
    "    results['tweet'] = dataset['tweet']\n",
    "\n",
    "    labels = []\n",
    "    scores = []\n",
    "\n",
    "    # Go through each tweet and evaluate\n",
    "    for tweet in results['tweet']:\n",
    "        ans = senti_pipeline(tweet)\n",
    "        # Append each dictionary result to corresponding list\n",
    "        labels.append(ans[0]['label'])\n",
    "        scores.append(ans[0]['score'])\n",
    "\n",
    "    # Create a column with list transformed into pd series\n",
    "    results['label'] = pd.Series(labels)\n",
    "    results['score'] = pd.Series(scores)\n",
    "\n",
    "    # Store results on new csv\n",
    "    results.to_csv('sa_tweets_eng_original.csv')\n",
    "else:\n",
    "    # Read csv containing tweets in english with already created scoring and labels\n",
    "    results = pd.read_csv('sa_tweets_eng_original.csv')\n",
    "    results = results.drop([\"Unnamed: 0\"], axis=1)\n",
    "    print(\"english sentiment analysis file already created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@joe_____schmoe @TonicMcD @PGATOUR @JustinThom...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hurricane Ian's reinsurance influence to exten...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.992381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@imoffensivers Still in Florida working on thi...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet     label     score\n",
       "0  @joe_____schmoe @TonicMcD @PGATOUR @JustinThom...  NEGATIVE  0.998637\n",
       "1  Hurricane Ian's reinsurance influence to exten...  POSITIVE  0.992381\n",
       "2  @imoffensivers Still in Florida working on thi...  NEGATIVE  0.998555"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test print\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate english tweets into Spanish using Google Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create translator class object\n",
    "translator = googletrans.Translator()\n",
    "# List to store tweets in spanish\n",
    "spanish = []\n",
    "\n",
    "# Pass each tweet as a parameter into the translator object and store results\n",
    "runnit = False\n",
    "if not exists(\"spanish_tweets_translated.csv\") or runnit:\n",
    "\n",
    "    # Create new dataframe to store spanish tweets\n",
    "    spanish_tweets = pd.DataFrame()\n",
    "\n",
    "    for tweet in results['tweet']:\n",
    "        trs = translator.translate(tweet, dest='es')\n",
    "        spanish.append(trs.text)\n",
    "\n",
    "    # Create column containing translated tweets\n",
    "    spanish_tweets['tweet'] = pd.Series(spanish)\n",
    "    spanish_tweets.to_csv(\"spanish_tweets_translated.csv\")\n",
    "else:\n",
    "    # Load csv containing translated tweets\n",
    "    spanish_tweets = pd.read_csv(\"spanish_tweets_translated.csv\")\n",
    "    spanish_tweets = spanish_tweets.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@joe_____schmoe @TonicMcD @PGATOUR @JustinThom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La influencia del reaseguro del huracán Ian se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@imoffensivers Todavía en Florida trabajando e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  @joe_____schmoe @TonicMcD @PGATOUR @JustinThom...\n",
       "1  La influencia del reaseguro del huracán Ian se...\n",
       "2  @imoffensivers Todavía en Florida trabajando e..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample print of df\n",
    "spanish_tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate back into english same spanish tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass each tweet as a parameter into the translator object and store results\n",
    "runnit = False\n",
    "en_tweets = []\n",
    "if not exists(\"sa_tweets_eng_snd.csv\") or runnit:\n",
    "\n",
    "    # Create new dataframe to store english tweets\n",
    "    english_tweets = pd.DataFrame()\n",
    "\n",
    "    for tweet in spanish_tweets['tweet']:\n",
    "        trs = translator.translate(tweet, dest='en')\n",
    "        en_tweets.append(trs.text)\n",
    "\n",
    "    # Create column containing translated tweets\n",
    "    english_tweets['tweet'] = pd.Series(en_tweets)\n",
    "    english_tweets.to_csv(\"sa_tweets_eng_snd.csv\")\n",
    "else:\n",
    "    # Load csv containing translated tweets\n",
    "    english_tweets = pd.read_csv(\"sa_tweets_eng_snd.csv\")\n",
    "    en_tweets = list(english_tweets['tweet'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@joe_____schmoe @TonicMcD @PGATOUR @JustinThom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The influence of Hurricane Ian reinsurance wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@imoffensivers Still in Florida working on thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  @joe_____schmoe @TonicMcD @PGATOUR @JustinThom...\n",
       "1  The influence of Hurricane Ian reinsurance wil...\n",
       "2  @imoffensivers Still in Florida working on thi..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print sample\n",
    "english_tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline on 2nd translated english tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnit = True\n",
    "if not exists(\"sa_tweets_eng_snd.csv\") or runnit:\n",
    "    labels = []\n",
    "    scores = []\n",
    "\n",
    "    # Go through each tweet and evaluate\n",
    "    for tweet in english_tweets['tweet']:\n",
    "        ans = senti_pipeline(tweet)\n",
    "        # Append each dictionary result to corresponding list\n",
    "        labels.append(ans[0]['label'])\n",
    "        scores.append(ans[0]['score'])\n",
    "\n",
    "    # Create a column with list transformed into pd series\n",
    "    english_tweets['label'] = pd.Series(labels)\n",
    "    english_tweets['score'] = pd.Series(scores)\n",
    "\n",
    "    # Store results on new csv\n",
    "    english_tweets.to_csv(\"sa_tweets_eng_snd.csv\")\n",
    "else:\n",
    "    # Read csv containing tweets in english with already created scoring and labels\n",
    "    english_tweets = pd.read_csv(\"sa_tweets_eng_snd.csv\")\n",
    "    english_tweets = english_tweets.drop([\"Unnamed: 0\"], axis=1)\n",
    "    print(\"english sentiment analysis second round file already created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@joe_____schmoe @TonicMcD @PGATOUR @JustinThom...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The influence of Hurricane Ian reinsurance wil...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.982135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@imoffensivers Still in Florida working on thi...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet     label     score\n",
       "0  @joe_____schmoe @TonicMcD @PGATOUR @JustinThom...  NEGATIVE  0.998329\n",
       "1  The influence of Hurricane Ian reinsurance wil...  POSITIVE  0.982135\n",
       "2  @imoffensivers Still in Florida working on thi...  NEGATIVE  0.998011"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out sample df\n",
    "english_tweets.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
